{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run remote VSCode / code-server on SPCS\n",
    "This notebook contains steps to perform the following:  \n",
    "- Optional: Configure Snowflake Roles & Resources for SPCS using python\n",
    "- Configure dockerfile for code-server & non-root miniconda access\n",
    "- Configure SPCS spec / service file\n",
    "- Push service file to @specs stage\n",
    "- Create service from staged spec file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Import packages\n",
    "Note: The following snowflake.core packages are only required if performing DDL operations in python. \n",
    "\n",
    "If you have already created the required Snowflake role, grants, and underlying objects using the tutorial referenced in the readme, these can be skipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/opt/conda/bin/python3\n",
    "import os\n",
    "\n",
    "from snowflake.core import Root\n",
    "from snowflake.core._common import CreateMode\n",
    "from snowflake.core.warehouse import Warehouse\n",
    "from snowflake.core.stage import (\n",
    "    Stage,\n",
    "    StageEncryption,\n",
    "    StageDirectoryTable,\n",
    ")\n",
    "\n",
    "from snowflake.core.grant import (\n",
    "    Grant,\n",
    "    Grantees,\n",
    "    Privileges,\n",
    "    Securables,\n",
    ")\n",
    "\n",
    "from snowflake.core.role import Role\n",
    "from snowflake.core.database import Database\n",
    "from snowflake.connector import connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Optional: Configure connection using local environment vars\n",
    "* place .env file with env vars in base directory of workspace \n",
    "* dotenv loads environment vars into python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load env vars\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS_ACCOUNT_ADMIN = {\n",
    "    \"account\": os.environ[\"snowflake_account\"],\n",
    "    \"user\": os.environ[\"snowflake_user\"],\n",
    "    \"password\": os.environ[\"snowflake_password\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SnowflakeConnection instance\n",
    "connection_acct_admin = connect(**CONNECTION_PARAMETERS_ACCOUNT_ADMIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Note that the following steps can be performed with SQL or Python. The tutorial referenced in the readme walks through these steps with SQL. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # create a root as the entry point for all object\n",
    "    root = Root(connection_acct_admin)\n",
    "\n",
    "    # CREATE ROLE CONTAINER_USER_ROLE\n",
    "    root.roles.create(Role(\n",
    "        name='CONTAINER_USER_ROLE',\n",
    "        comment='My role to use container',\n",
    "    ))\n",
    "\n",
    "    # GRANT CREATE DATABASE ON ACCOUNT TO ROLE CONTAINER_USER_ROLE\n",
    "    # GRANT CREATE WAREHOUSE ON ACCOUNT TO ROLE CONTAINER_USER_ROLE;\n",
    "    # GRANT CREATE COMPUTE POOL ON ACCOUNT TO ROLE CONTAINER_USER_ROLE;\n",
    "    # GRANT CREATE INTEGRATION ON ACCOUNT TO ROLE CONTAINER_USER_ROLE;\n",
    "    # GRANT MONITOR USAGE ON ACCOUNT TO  ROLE  CONTAINER_USER_ROLE;\n",
    "    # GRANT BIND SERVICE ENDPOINT ON ACCOUNT TO ROLE CONTAINER_USER_ROLE;\n",
    "    root.grants.grant(Grant(\n",
    "        grantee=Grantees.role('CONTAINER_USER_ROLE'),\n",
    "        securable=Securables.current_account,\n",
    "        privileges=[Privileges.create_database,\n",
    "                    Privileges.create_warehouse,\n",
    "                    Privileges.create_compute_pool,\n",
    "                    Privileges.create_integration,\n",
    "                    Privileges.monitor_usage,\n",
    "                    Privileges.bind_service_endpoint\n",
    "                    ],\n",
    "    ))\n",
    "\n",
    "    # GRANT IMPORTED PRIVILEGES ON DATABASE snowflake TO ROLE CONTAINER_USER_ROLE;\n",
    "    root.grants.grant(Grant(\n",
    "        grantee=Grantees.role('CONTAINER_USER_ROLE'),\n",
    "        securable=Securables.database('snowflake'),\n",
    "        privileges=[Privileges.imported_privileges\n",
    "                    ],\n",
    "    ))\n",
    "\n",
    "    # grant role CONTAINER_USER_ROLE to role ACCOUNTADMIN;\n",
    "    root.grants.grant(Grant(\n",
    "        grantee=Grantees.role('ACCOUNTADMIN'),\n",
    "        securable=Securables.role('CONTAINER_USER_ROLE')\n",
    "    ))\n",
    "\n",
    "    # USE ROLE CONTAINER_USER_ROLE\n",
    "    root.session.use_role(\"CONTAINER_USER_ROLE\")\n",
    "\n",
    "    # CREATE OR REPLACE DATABASE CONTAINER_HOL_DB;\n",
    "    root.databases.create(Database(\n",
    "        name=\"CONTAINER_HOL_DB\",\n",
    "        comment=\"This is a Container Quick Start Guide database\"\n",
    "    ), mode=CreateMode.or_replace)\n",
    "\n",
    "    # CREATE OR REPLACE WAREHOUSE CONTAINER_HOL_WH\n",
    "    #   WAREHOUSE_SIZE = XSMALL\n",
    "    #   AUTO_SUSPEND = 120\n",
    "    #   AUTO_RESUME = TRUE;\n",
    "    root.warehouses.create(Warehouse(\n",
    "        name=\"CONTAINER_HOL_WH\",\n",
    "        warehouse_size=\"XSMALL\",\n",
    "        auto_suspend=120,\n",
    "        auto_resume=\"true\",\n",
    "        comment=\"This is a Container Quick Start Guide warehouse\"\n",
    "    ), mode=CreateMode.or_replace)\n",
    "\n",
    "    # CREATE STAGE IF NOT EXISTS specs\n",
    "    # ENCRYPTION = (TYPE='SNOWFLAKE_SSE');\n",
    "    root.databases['CONTAINER_HOL_DB'].schemas[CONNECTION_PARAMETERS_ACCOUNT_ADMIN.get(\"schema\")].stages.create(\n",
    "        Stage(\n",
    "            name=\"specs\",\n",
    "            encryption=StageEncryption(type=\"SNOWFLAKE_SSE\")\n",
    "    ))\n",
    "\n",
    "    # CREATE STAGE IF NOT EXISTS volumes\n",
    "    # ENCRYPTION = (TYPE='SNOWFLAKE_SSE')\n",
    "    # DIRECTORY = (ENABLE = TRUE);\n",
    "    root.databases['CONTAINER_HOL_DB'].schemas[CONNECTION_PARAMETERS_ACCOUNT_ADMIN.get(\"schema\")].stages.create(\n",
    "        Stage(\n",
    "            name=\"volumes\",\n",
    "            encryption=StageEncryption(type=\"SNOWFLAKE_SSE\"),\n",
    "            directory_table=StageDirectoryTable(enable=True)\n",
    "    ))\n",
    "    # create collection objects as the entry\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    connection_acct_admin.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Setup Steps (Skipped/pre-existing for the purposes of this demo)\n",
    "Reference: [SPCS quickstart](https://quickstarts.snowflake.com/guide/intro_to_snowpark_container_services/index.html)\n",
    "\n",
    "1. setting up security integrations\n",
    "  - configure ingress -- base case is an oauth config to snowservices_ingress\n",
    "2. setting up network rule\n",
    "  - defines ingress/egress IPs, ports\n",
    "  - typically execute only once, during initial SPCS configuration\n",
    "3. setting up external access integration\n",
    "  - param for external access integration is previously created network rule\n",
    "4. Create image registry within SPCS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test connection for container user role\n",
    "- container services are scoped to specific database, schema, and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS_CONTAINER_USER_ROLE = {\n",
    "    \"account\": os.environ[\"snowflake_account\"],\n",
    "    \"user\": os.environ[\"snowflake_user\"],\n",
    "    \"password\": os.environ[\"snowflake_password\"],\n",
    "    \"role\": \"CONTAINER_USER_ROLE\",\n",
    "    \"warehouse\": \"CONTAINER_HOL_WH\",\n",
    "    \"Database\": \"CONTAINER_HOL_DB\",\n",
    "    \"Schema\": \"public\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect as CONTAINER_USE_ROLE\n",
    "connection_container_user_role = connect(**CONNECTION_PARAMETERS_CONTAINER_USER_ROLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Registry Usage\n",
    "- MFA based login command, below\n",
    "- Create image registry in prior step, or use existing; see reference (https://docs.snowflake.com/en/developer-guide/snowpark-container-services/working-with-registry-repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! snow spcs image-registry token --format=JSON | \\\n",
    "docker login sfsenorthamerica-demo-cgoyette.registry.snowflakecomputing.com -u 0sessiontoken --password-stdin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build docker image - linuxserver.io/code-server\n",
    "- starting with base image from [lscr.io](https://docs.linuxserver.io/images/docker-code-server/#application-setup)\n",
    "- added steps for miniconda installation & expose conda on path for non-root users\n",
    "  - Reference: https://stackoverflow.com/questions/58269375/how-to-install-packages-with-miniconda-in-dockerfile\n",
    "- see included dockerfile in /src/code-server-r-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code-server-r-py.yaml dockerfile            dockerfile.bak\n"
     ]
    }
   ],
   "source": [
    "# Build the Docker Image -- Run these commands in a terminal\n",
    "! ls ./src/code-server-r-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the command below to reflect the local repo you'd like to build the docker image into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## the following command will build an image from the dockerfile in the current directory, and name it cgoyette/code-server\n",
    "! docker build -t cgoyette/code-server-r ./src/code-server-r-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Observe Image in local docker repo\n",
    "#### Modify this to reflect your repo name\n",
    "! docker image list | grep \"cgoyette/code-server-r-py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional / Best practice: Tag image in Docker\n",
    "Note image ID below, from prior step / local image after pull\n",
    "\n",
    "Home folder will differ on your local. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker tag cgoyette/code-server-r-py sfsenorthamerica-demo-cgoyette.registry.snowflakecomputing.com/container_hol_db/public/image_repo/code-server-r-py:amd64-latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker: push created image to your SPCS registry\n",
    "After completing this step, use 'docker image list' to check that it exists in your registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note: using tag from prior step, I push my local image to the SPCS image registry I've created \n",
    "## modify this step to reflect your image registry name and local repo\n",
    "! docker push sfsenorthamerica-demo-cgoyette.registry.snowflakecomputing.com/container_hol_db/public/image_repo/code-server-r-py:amd64-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker image list | grep \"sfsenorthamerica-demo-cgoyette.registry.snowflakecomputing.com/container_hol_db/public/image_repo/code-server-r-py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Test running the image, locally\n",
    "- CG note: Works as expected\n",
    "- Service available on local host\n",
    "\n",
    "Note that this requires that the image architecture matches the architecture of your local machine. Docker buildx is also an option, if you have a Mac laptop with an ARM-based M chipset, and want to test locally without managing multiple images with different architectures for testing purposes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "docker run -d \\\n",
    "  --name=code-server-r-py \\\n",
    "  -e PUID=1000 \\\n",
    "  -e PGID=1000 \\\n",
    "  -e TZ=Etc/UTC \\\n",
    "  -e PASSWORD=password \\ #not secure\n",
    "  -e SUDO_PASSWORD=password \\ #not secure\n",
    "  -e PROXY_DOMAIN=code-server-r-py.my.domain \\\n",
    "  -e DEFAULT_WORKSPACE=/config/workspace  \\\n",
    "  -p 8443:8443 \\\n",
    "  -v ~/config:/config \\\n",
    "  --restart unless-stopped \\\n",
    "  lscr.io/linuxserver/code-server-r-py:latest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure and Push the Spec YAML\n",
    "Services in Snowpark Container Services are defined using YAML files. These YAML files configure all of the various parameters, etc. needed to run the containers within your Snowflake account. \n",
    "\n",
    "These YAMLs support a large number of configurable parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref/Example: service spec for code server\n",
    "* see yaml file\n",
    "* /src/code-server-r-py/code-server-r-py.yaml  \n",
    "* [Service Spec Reference](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/specification-reference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push spec file to stage\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Snowcli to push the yaml spec to your Database's @specs stage \n",
    "\n",
    "Note: if you would like to modify an existing service, take the following steps:\n",
    "1. Suspend existing/running service\n",
    "2. Update spec yaml file as needed\n",
    "3. Perform the following copy operation to overwrite existing spec file\n",
    "4. Resume service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! snow object stage copy ./src/code-server-r-py/code-server-r-py.yaml @specs --overwrite --connection CONTAINER_hol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Create & test service"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#SQL\n",
    "## This command is also in spcs_configuration_management.sql \n",
    "\n",
    "CREATE SERVICE CONTAINER_HOL_DB.PUBLIC.CODE_SERVER_R_PY_DEPS\n",
    "IN COMPUTE POOL CONTAINER_HOL_POOL\n",
    "from @specs\n",
    "specification_file='code-server-r-py.yaml'\n",
    "external_access_integrations = (ALLOW_ALL_EAI);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SHOW SERVICES;\n",
    "\n",
    "DESCRIBE SERVICE code_server_r_py_deps;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "DESCRIBE SERVICE code_server_r_py_deps;\n",
    "\n",
    "SHOW SERVICES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check status\n",
    "-- see scratch.sql for sql commands, and to execute from worksheet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---run in terminal\n",
    "---get service status\n",
    "CALL SYSTEM$GET_SERVICE_STATUS('CONTAINER_HOL_DB.PUBLIC.code_server_r_py_deps');\n",
    "\n",
    "---show endpoint; use for browser-based ingress to this long-running interactive service\n",
    "SHOW ENDPOINTS IN SERVICE CODE_SERVER_R_PY_DEPS;\n",
    "\n",
    "---shut down/clean up\n",
    "ALTER SERVICE CODE_SERVER_R_PY_DEPS SUSPEND;\n",
    "\n",
    "ALTER COMPUTE POOL CONTAINER_HOL_POOL SUSPEND;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "---retrieve logs, if you have the need\n",
    "CALL SYSTEM$GET_SERVICE_LOGS('CONTAINER_HOL_DB.PUBLIC.code_server_r_py_deps', '0', 'code-server-r-py',100);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "### Access to running service\n",
    "The following command will return the exposed endpoint(s) of the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "#SQL \n",
    "SHOW ENDPOINTS IN SERVICE code_server_r_py_deps;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the URL, and paste it in your browser.   \n",
    "You will be asked to login to your Snowflake, after which you should successfully see your code-server instance running, all inside of Snowflake!   \n",
    "\n",
    "Note, to access the service the user logging in must have the CONTAINER_USER_ROLE AND their default role cannot be ACCOUNTADMIN, SECURITYADMIN, or ORGADMIN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps / Testing: Upload and Modify a Notebook\n",
    "CG Note: the following is lifted from the quickstart, but the behavior described has been validated, e.g.,\n",
    "- One does not need to suspend or resume an SPCS service to observe new files copied to stage\n",
    "- **Note: in service spec yaml, set the user ID and group ID to the default UID/GID for the hosted service. For code-server, this is 911 for both.** This enables r/w access to/from the stage and files accessible via the service.\n",
    "\n",
    "---\n",
    "\n",
    "Notice that in our spec YAML file we mounted the @volumes/jupyter-snowpark internal stage location to our workspace/stage directory inside of our running container. \n",
    "\n",
    "What this means is that we will use our internal stage @volumes to persist and store artifacts from our container. If you go check out the @volumes stage in Snowsight, you'll see that when we created our jupyter_snowpark_service, a folder was created in our stage: @volumes/jupyter-snowpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, any file that is uploaded to @volumes/jupyter-snowpark will be available inside of our container in the /home/jupyter directory, and vice versa. Read more about volume mounts in the documentation. To test this out, let's upload the sample Jupyter notebook that is in our source code repo at .../sfguide-intro-to-snowpark-container-services/src/jupyter-snowpark/sample_notebook.ipynb. To do this you can either  \n",
    "1. Click on the jupyter-snowpark directory in Snowsight, click the blue + Files button and drag/browse to sample_notebook.ipynb. Click Upload. Navigate to your Jupyter service UI in your browser, click the refresh arrow and you should now see your notebook available!  OR   \n",
    "2. Upload sample_notebook.ipynb to @volumes/jupyter-snowpark using SnowCLI OR \n",
    "3. Upload sample_notebook.ipynb directly in your Jupyter service on the home screen by clicking the Upload button. If you now navigate back to @volumes/jupyter-snowpark in Snowsight, our run an ls @volumes/jupyter-snowpark SQL command, you should see your sample_notebook.ipynb file listed. Note you may need to hit the Refresh icon in Snowsight for the file to appear.  \n",
    "\n",
    "What we've done is now created a Jupyter notebook which we can modify in our service, and the changes will be persisted in the file because it is using a stage-backed volume. Let's take a look at the contents of our sample_notebook.ipynb. Open up the notebook in your Jupyter service:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_spcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
